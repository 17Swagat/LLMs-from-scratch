{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2853bb5c",
   "metadata": {},
   "source": [
    "# **Book [Temp]**\n",
    "> Right now the loaded model seems to be off. The outputs are not as expected. \n",
    "\n",
    "> It looks like the model pretrained weights are not loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec6f3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#####################################\n",
    "# Chapter 3\n",
    "#####################################\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Chapter 4\n",
    "#####################################\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed-forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c53d40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n_heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False        # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62909328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbc42577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "# Loading PreTrained GPT2 124M Model Weights\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "model_dir = '../../ch05/00_ME-Experimenting/gpt2/124M/'\n",
    "tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
    "params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "print(settings)\n",
    "print(params.keys()) # Model parameters loaded successfully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2eab854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "482547c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # New (not in book): numerical stability tip to get equivalent results on mps device\n",
    "            # subtract rowwise max before softmax\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3eaf2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9427aed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you along at a rate that moves your limbs down a step, increasing the chances that you fall. It creates an additional increase of\n",
      "Every effort moves you backwards through an era where everything has changed...I mean the music stopped moving over me (Laughs), but all it did was\n",
      "Every effort moves you forward but each one comes with risks and you only need good, healthy support of your brain to make you through tough times.\n",
      "Every effort moves you more quickly through this processâ€¦when all else failsâ€¦it all slows down considerablyðŸ¦ðŸ¦5. Don't lose time trying\n",
      "Every effort moves you back. After all, your entire mission was about to pass away... but you're fighting for it!\" \"Aha!\n",
      "Every effort moves you along with it.\"ðŸ¦ðŸ¦AdvertisementðŸ¦ðŸ¦Falling victim by 20 (and a full 16 more in 2016, after an\n",
      "Every effort moves you backwards. Even if it doesn't affect your mind or experience then it does change them in terms of yourself and your sense of\n",
      "Every effort moves you through every game to bring you the action you play on your new consoles. For PlayStationÂ® 4, our developers built a custom\n",
      "Every effort moves you forward in your endeavor, while at the same time allowing you to focus less and less your brain to do exactly where it takes\n",
      "Every effort moves you to the highest heaven; therefore every effort moves you upward into all eternity: therefore the God to which I have referred me shall\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    token_ids = generate(\n",
    "        model=gpt,\n",
    "        idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "        max_new_tokens=25,\n",
    "        context_size=NEW_CONFIG[\"context_length\"],\n",
    "        top_k=50,\n",
    "        temperature=1.5\n",
    "    )\n",
    "    print(token_ids_to_text(token_ids, tokenizer).replace('\\n', 'ðŸ¦'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03fae9",
   "metadata": {},
   "source": [
    "# **Prev Chapter STUFF âŒ**\n",
    "| ðŸ“Œ Not sure what but I'm `doing something wrong`, due to which correct `OpenAI` Pretrained weights are not loaded properly. |\n",
    "| --- |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff71cfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\$LLMS\\LLMs-from-scratch\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "# Loading PreTrained GPT2 124M Model Weights\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "model_dir = '../../ch05/00_ME-Experimenting/gpt2/124M/'\n",
    "tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
    "params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "print(settings)\n",
    "print(params.keys()) # Model parameters loaded successfully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0c33f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# (OLDER) GPT-2 small (124M) config\n",
    "GPT_CONFIG_124M = { \n",
    "    \"vocab_size\": 50257, \n",
    "    \"context_length\": 256, #1024, \n",
    "    \"emb_dim\": 768, \n",
    "    \"n_heads\": 12, \n",
    "    \"n_layers\": 4, #12,  # Transformer-Block-Layers\n",
    "    \"drop_rate\": 0.1, \n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        self.eps = 1e-5\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        '''x: 3D Tensor'''\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, keepdim=True, unbiased=False) # unbiased=False => Division by `n`, rather than `n-1`\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return (x_norm * self.scale + self.shift)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(config['emb_dim'], 4 * config['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear( 4 * config['emb_dim'], config['emb_dim'])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return (0.5 * x * (1 + torch.tanh(\n",
    "            (torch.sqrt(torch.tensor(2/torch.pi))) + (x + 0.044715 * torch.pow(x, 3))\n",
    "        )))\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, n_heads, context_length, dropout=0.5, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % n_heads == 0)\n",
    "\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.d_head = (d_out // n_heads)\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.register_buffer('mask', torch.ones(context_length, context_length).triu(1).bool())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''x: 3D. x => (batch_size, num_tokens, token_embed)'''\n",
    "        b, n_tokens, token_embed = x.shape\n",
    "        assert self.d_in == token_embed\n",
    "        \n",
    "        Q = self.W_q(x) # (b, n_tokens, d_out)\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        Q = Q.view(b, n_tokens, self.n_heads, self.d_head) # (b, n_tokens, n_heads, d_head)\n",
    "        K = K.view(b, n_tokens, self.n_heads, self.d_head) \n",
    "        V = V.view(b, n_tokens, self.n_heads, self.d_head) \n",
    "\n",
    "        Q = Q.transpose(1, 2) # (b, n_heads, n_tokens, d_head)\n",
    "        K = K.transpose(1, 2)\n",
    "        V = V.transpose(1, 2)\n",
    "\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-1, -2)) / self.d_head**0.5 #K.shape[-1]**0.5\n",
    "        attn_scores = attn_scores.masked_fill(self.mask[: n_tokens, : n_tokens], -torch.inf)\n",
    "        attn_weights = attn_scores.softmax(-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vectors = attn_weights @ V\n",
    "        context_vectors = context_vectors.transpose(1, 2)\n",
    "        context_vectors = context_vectors.contiguous().view(b, n_tokens, self.d_out)\n",
    "        return self.out_proj(context_vectors)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.attn = MultiheadAttention(\n",
    "            d_in=cfg['emb_dim'],    # 768\n",
    "            d_out=cfg['emb_dim'],   # 768\n",
    "            n_heads=cfg['n_heads'], # 12\n",
    "            context_length=cfg['context_length'], # 1024\n",
    "            dropout=cfg['drop_rate'], # 0.1\n",
    "            qkv_bias=cfg['qkv_bias']\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm_1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm_2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.dropout = nn.Dropout(cfg['drop_rate'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Part 1:\n",
    "        shortcut = x\n",
    "        x = self.norm_1(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        # Part 2:\n",
    "        shortcut = x\n",
    "        x = self.norm_2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(config['vocab_size'], config['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(config['context_length'], config['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(config['drop_rate'])\n",
    "        self.transf_layers = nn.Sequential(*[TransformerBlock(config) for _ in range(config['n_layers'])])\n",
    "        self.final_norm = LayerNorm(config['emb_dim'])\n",
    "        self.out_head = nn.Linear(config['emb_dim'], config['vocab_size'], bias=False)\n",
    "    \n",
    "    def forward(self, x, show_info=False):\n",
    "        '''x: 2D Matrix'''\n",
    "        batch_size, seq_len = x.shape \n",
    "        tok_emb = self.tok_emb(x) \n",
    "        pos_emb = self.pos_emb(\n",
    "            torch.arange(seq_len).to(x.device)  # Ensure pos indices are on the same device as x\n",
    "        )\n",
    "        x = tok_emb + pos_emb\n",
    "        if show_info:\n",
    "            print(f'Token-Embed(shape): {tok_emb.shape}')\n",
    "            print(f'POS-Embed(shape): {pos_emb.shape}')\n",
    "            print(f'i/p Before TransfBlocks(shape): {x.shape}')\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.transf_layers(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4278b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 Model Configurations\n",
    "model_configs = { \n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12}, \n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16}, \n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20}, \n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# GPT2 124M Base Configuration:\n",
    "MODEL_CONFIG = {\n",
    "    'vocab_size': 50257, \n",
    "    'context_length': 256, \n",
    "    'emb_dim': 768, \n",
    "    'n_heads': 12, \n",
    "    'n_layers': 12, \n",
    "    'drop_rate': 0.1, \n",
    "    'qkv_bias': True, \n",
    "}\n",
    "\n",
    "MODEL_CONFIG.update({\n",
    "    'context_length': settings['n_ctx'],\n",
    "    'emb_dim': settings['n_embd'],\n",
    "})\n",
    "\n",
    "gpt = GPTModel(MODEL_CONFIG) # Uninitialized weights\n",
    "gpt.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea4b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading pretrained weights from TensorFlow checkpoint \n",
    "import numpy as np\n",
    "\n",
    "def assignParams(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch: {left.shape} vs {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assignParams(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assignParams(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.transf_layers[b].attn.W_q.weight = assignParams(\n",
    "            gpt.transf_layers[b].attn.W_q.weight, q_w.T)\n",
    "        gpt.transf_layers[b].attn.W_k.weight = assignParams(\n",
    "            gpt.transf_layers[b].attn.W_k.weight, k_w.T)\n",
    "        gpt.transf_layers[b].attn.W_v.weight = assignParams(\n",
    "            gpt.transf_layers[b].attn.W_v.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.transf_layers[b].attn.W_q.bias = assignParams(\n",
    "            gpt.transf_layers[b].attn.W_q.bias, q_b)\n",
    "        gpt.transf_layers[b].attn.W_k.bias = assignParams(\n",
    "            gpt.transf_layers[b].attn.W_k.bias, k_b)\n",
    "        gpt.transf_layers[b].attn.W_v.bias = assignParams(\n",
    "            gpt.transf_layers[b].attn.W_v.bias, v_b)\n",
    "\n",
    "        gpt.transf_layers[b].attn.out_proj.weight = assignParams(\n",
    "            gpt.transf_layers[b].attn.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transf_layers[b].attn.out_proj.bias = assignParams(\n",
    "            gpt.transf_layers[b].attn.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.transf_layers[b].ff.layers[0].weight = assignParams(\n",
    "            gpt.transf_layers[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.transf_layers[b].ff.layers[0].bias = assignParams(\n",
    "            gpt.transf_layers[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.transf_layers[b].ff.layers[2].weight = assignParams(\n",
    "            gpt.transf_layers[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transf_layers[b].ff.layers[2].bias = assignParams(\n",
    "            gpt.transf_layers[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.transf_layers[b].norm_1.scale = assignParams(\n",
    "            gpt.transf_layers[b].norm_1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.transf_layers[b].norm_1.shift = assignParams(\n",
    "            gpt.transf_layers[b].norm_1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.transf_layers[b].norm_2.scale = assignParams(\n",
    "            gpt.transf_layers[b].norm_2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.transf_layers[b].norm_2.shift = assignParams(\n",
    "            gpt.transf_layers[b].norm_2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assignParams(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assignParams(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assignParams(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f39b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Model:\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # New (not in book): numerical stability tip to get equivalent results on mps device\n",
    "            # subtract rowwise max before softmax\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6a87c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "every effort.\"ðŸ¦ðŸ¦One recent analysis showed that the number of refugees fleeing the country's deadliest civil war could increase substantially if both Syria\n",
      "every effort,\" he said. Asked why the government tried trying to solve all this on Saturday, Barstow explained that while his job\n",
      "every effort. If some of it is done correctly (I hope that he's not!) I may even have given myself the time time\n",
      "every effort at preventing death,\" says Dr. Sirota. More research needs to be done over the long term, for instance where\n",
      "every effort is still under process, so the public's feedback cannot be verified and no guarantees to receive changes. For more information about how\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# token_ids = generate(\n",
    "#     model=gpt,\n",
    "#     idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "#     max_new_tokens=25,\n",
    "#     context_size=MODEL_CONFIG[\"context_length\"],\n",
    "#     top_k=50,\n",
    "#     temperature=1.5\n",
    "# )\n",
    "\n",
    "for i in range(5):\n",
    "    token_ids = generate(\n",
    "        model=gpt,\n",
    "        idx=text_to_token_ids(\"every effort\", tokenizer).to(device),\n",
    "        max_new_tokens=25,\n",
    "        context_size=MODEL_CONFIG[\"context_length\"],\n",
    "        top_k=50,\n",
    "        temperature=1.5\n",
    "    )\n",
    "    print(token_ids_to_text(token_ids, tokenizer).replace('\\n', 'ðŸ¦'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e897bd0",
   "metadata": {},
   "source": [
    "# **FineTurning For Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9657282",
   "metadata": {},
   "source": [
    "## **Dataset Download:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92ca34cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection\\SMSSpamCollection.tsv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport urllib.request\\nimport zipfile\\nimport os\\nfrom pathlib import Path\\n\\nurl = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\\nzip_path = \"sms_spam_collection.zip\"\\nextracted_path = \"sms_spam_collection\"\\ndata_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\\n\\ndef download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\\n    if data_file_path.exists():\\n        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\\n        return\\n\\n    # Downloading the file\\n    with urllib.request.urlopen(url) as response:\\n        with open(zip_path, \"wb\") as out_file:\\n            out_file.write(response.read())\\n\\n    # Unzipping the file\\n    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\\n        zip_ref.extractall(extracted_path)\\n\\n    # Add .tsv file extension\\n    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\\n    os.rename(original_file_path, data_file_path)\\n    print(f\"File downloaded and saved as {data_file_path}\")\\n\\ntry:\\n    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\\nexcept (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\\n    print(f\"Primary URL failed: {e}. Trying backup URL...\")\\n    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\\n    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @rasbt: Downloading the SMS Spam Collection Dataset:->\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    response = requests.get(url, stream=True, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    with open(zip_path, \"wb\") as out_file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                out_file.write(chunk)\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (requests.exceptions.RequestException, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\n",
    "\n",
    "\n",
    "# The book originally used the following code below\n",
    "# However, urllib uses older protocol settings that\n",
    "# can cause problems for some readers using a VPN.\n",
    "# The `requests` version above is more robust\n",
    "# in that regard.\n",
    "\n",
    "\"\"\"\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "059cda4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "df.to_csv('sms_spam_collection/SMSSpamCollection.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "03c7539e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0662fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] == 'spam'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "27a737bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ãœ thk of wat to eat tonight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pls give her the food preferably pap very slow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thts god's gift for birds as humans hav some n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok but tell me half an hr b4 u come i need 2 p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lor. Anyway i thk we cant get tickets now c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>ham</td>\n",
       "      <td>Do you like shaking your booty on the dance fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh ! A half hour is much longer in Syria than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm ok. Will do my part tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4361</th>\n",
       "      <td>ham</td>\n",
       "      <td>Night sweet, sleep well! I've just been to see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>747 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "4788   ham                       Ãœ thk of wat to eat tonight.\n",
       "4695   ham  Pls give her the food preferably pap very slow...\n",
       "2925   ham  Thts god's gift for birds as humans hav some n...\n",
       "2751   ham  Ok but tell me half an hr b4 u come i need 2 p...\n",
       "3990   ham  Ok lor. Anyway i thk we cant get tickets now c...\n",
       "...    ...                                                ...\n",
       "2651   ham  Do you like shaking your booty on the dance fl...\n",
       "1335   ham  Oh ! A half hour is much longer in Syria than ...\n",
       "3857   ham                   I'm ok. Will do my part tomorrow\n",
       "4361   ham  Night sweet, sleep well! I've just been to see...\n",
       "4862   ham                             Nokia phone is lovly..\n",
       "\n",
       "[747 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = df[df['label'] == 'spam'].shape[0]\n",
    "df[df['label'] == 'ham'].sample(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "700241ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>ham</td>\n",
       "      <td>Watching cartoon, listening music &amp;amp; at eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>ham</td>\n",
       "      <td>K sure am in my relatives home. Sms me de. Pls:-)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>ham</td>\n",
       "      <td>New Theory: Argument wins d SITUATION, but los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh did you charge camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok give me 5 minutes I think I see her. BTW yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>spam</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "4869   ham  Watching cartoon, listening music &amp; at eve...\n",
       "5181   ham  K sure am in my relatives home. Sms me de. Pls:-)\n",
       "4884   ham  New Theory: Argument wins d SITUATION, but los...\n",
       "5167   ham                           Oh did you charge camera\n",
       "550    ham  Ok give me 5 minutes I think I see her. BTW yo...\n",
       "...    ...                                                ...\n",
       "5537  spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a Balanced Dataset ||=>  \n",
    "# Got, [ham: 4825 & spam: 747]\n",
    "# So, a easier way to creaed a balanced dataset would be get 747 random `ham` samples.\n",
    "\n",
    "num_samples = df[df['label'] == 'spam'].shape[0]\n",
    "notSpamsamples = df[df['label'] == 'ham'].sample(num_samples)\n",
    "# notSpamsamples.shape # (747, 2)\n",
    "balanced_df = pd.concat([notSpamsamples, df[df['label'] == 'spam']])\n",
    "# balanced_df.shape # (1494, 2)\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "53ebcdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>ham</td>\n",
       "      <td>Watching cartoon, listening music &amp;amp; at eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>ham</td>\n",
       "      <td>K sure am in my relatives home. Sms me de. Pls:-)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>ham</td>\n",
       "      <td>New Theory: Argument wins d SITUATION, but los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh did you charge camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok give me 5 minutes I think I see her. BTW yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>spam</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "4869   ham  Watching cartoon, listening music &amp; at eve...\n",
       "5181   ham  K sure am in my relatives home. Sms me de. Pls:-)\n",
       "4884   ham  New Theory: Argument wins d SITUATION, but los...\n",
       "5167   ham                           Oh did you charge camera\n",
       "550    ham  Ok give me 5 minutes I think I see her. BTW yo...\n",
       "...    ...                                                ...\n",
       "5537  spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eae766ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yup but it's not giving me problems now so may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>spam</td>\n",
       "      <td>YOU VE WON! Your 4* Costa Del Sol Holiday or Â£...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah it's jus rite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>ham</td>\n",
       "      <td>Do you mind if I ask what happened? You dont h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>ham</td>\n",
       "      <td>What * u wearing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>spam</td>\n",
       "      <td>HOT LIVE FANTASIES call now 08707509020 Just 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>ham</td>\n",
       "      <td>* Will have two more cartons off u and is very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>spam</td>\n",
       "      <td>18 days to Euro2004 kickoff! U will be kept in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wat r u doing?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "4828   ham  Yup but it's not giving me problems now so may...\n",
       "5201  spam  YOU VE WON! Your 4* Costa Del Sol Holiday or Â£...\n",
       "5541   ham                              Yeah it's jus rite...\n",
       "647    ham  Do you mind if I ask what happened? You dont h...\n",
       "1139   ham                                  What * u wearing?\n",
       "...    ...                                                ...\n",
       "2992  spam  HOT LIVE FANTASIES call now 08707509020 Just 2...\n",
       "2218   ham  * Will have two more cartons off u and is very...\n",
       "1050  spam  18 days to Euro2004 kickoff! U will be kept in...\n",
       "3864  spam  Oh my god! I've found your number again! I'm s...\n",
       "1558   ham                                     Wat r u doing?\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = balanced_df.sample(len(balanced_df))\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cc941f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup but it's not giving me problems now so may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>0</td>\n",
       "      <td>YOU VE WON! Your 4* Costa Del Sol Holiday or Â£...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>1</td>\n",
       "      <td>Yeah it's jus rite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>1</td>\n",
       "      <td>Do you mind if I ask what happened? You dont h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1</td>\n",
       "      <td>What * u wearing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>0</td>\n",
       "      <td>HOT LIVE FANTASIES call now 08707509020 Just 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>1</td>\n",
       "      <td>* Will have two more cartons off u and is very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>0</td>\n",
       "      <td>18 days to Euro2004 kickoff! U will be kept in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>1</td>\n",
       "      <td>Wat r u doing?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "4828      1  Yup but it's not giving me problems now so may...\n",
       "5201      0  YOU VE WON! Your 4* Costa Del Sol Holiday or Â£...\n",
       "5541      1                              Yeah it's jus rite...\n",
       "647       1  Do you mind if I ask what happened? You dont h...\n",
       "1139      1                                  What * u wearing?\n",
       "...     ...                                                ...\n",
       "2992      0  HOT LIVE FANTASIES call now 08707509020 Just 2...\n",
       "2218      1  * Will have two more cartons off u and is very...\n",
       "1050      0  18 days to Euro2004 kickoff! U will be kept in...\n",
       "3864      0  Oh my god! I've found your number again! I'm s...\n",
       "1558      1                                     Wat r u doing?\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing: [ham: 1] ; [spam: 0]\n",
    "dataset_df['label'] = dataset_df['label'].map({\n",
    "    'ham': 1,\n",
    "    'spam': 0\n",
    "})\n",
    "\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "14cb3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Val, Test Subsets:\n",
    "split_ratio = 0.7\n",
    "split = int(split_ratio * len(dataset_df))\n",
    "\n",
    "train_df = dataset_df[: split]\n",
    "val_test_df = dataset_df[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ed182260",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.7\n",
    "split = int(split_ratio * len(val_test_df))\n",
    "val_df = val_test_df[:split]\n",
    "test_df = val_test_df[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "241056e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "314\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df)) \n",
    "print(len(val_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "da6855e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup but it's not giving me problems now so may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>0</td>\n",
       "      <td>YOU VE WON! Your 4* Costa Del Sol Holiday or Â£...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>1</td>\n",
       "      <td>Yeah it's jus rite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>1</td>\n",
       "      <td>Do you mind if I ask what happened? You dont h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1</td>\n",
       "      <td>What * u wearing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>0</td>\n",
       "      <td>FREE camera phones with linerental from 4.49/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>1</td>\n",
       "      <td>He says he'll give me a call when his friend's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>0</td>\n",
       "      <td>449050000301 You have won a Â£2,000 price! To c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>1</td>\n",
       "      <td>Iâ€˜m parked next to a MINI!!!! When are you com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>1</td>\n",
       "      <td>Nt only for driving even for many reasons she ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "4828      1  Yup but it's not giving me problems now so may...\n",
       "5201      0  YOU VE WON! Your 4* Costa Del Sol Holiday or Â£...\n",
       "5541      1                              Yeah it's jus rite...\n",
       "647       1  Do you mind if I ask what happened? You dont h...\n",
       "1139      1                                  What * u wearing?\n",
       "...     ...                                                ...\n",
       "2189      0  FREE camera phones with linerental from 4.49/m...\n",
       "313       1  He says he'll give me a call when his friend's...\n",
       "1118      0  449050000301 You have won a Â£2,000 price! To c...\n",
       "260       1  Iâ€˜m parked next to a MINI!!!! When are you com...\n",
       "4738      1  Nt only for driving even for many reasons she ...\n",
       "\n",
       "[1045 rows x 2 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c7fe82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Trainset, Validset, Testset:\n",
    "train_df.to_csv('my-dataset/train.csv', index=False)\n",
    "val_df.to_csv('my-dataset/val.csv', index=False)\n",
    "test_df.to_csv('my-dataset/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5d6d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3567f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, pad_id=50256, max_Length=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.encoding = [tokenizer.encode(text) for text in self.df['text']]\n",
    "        if max_Length is None:\n",
    "            max_Length = self._getMaxlength()\n",
    "\n",
    "            for i, encoding in enumerate(self.encoding):\n",
    "                # Padding:\n",
    "                self.encoding[i] += [pad_id] * (max_Length - len(encoding))\n",
    "        else:\n",
    "            for i, encoding in enumerate(self.encoding):\n",
    "                self.encoding[i] = encoding[: max_Length]\n",
    "                # encoding = encoding[: max_Length]\n",
    "            \n",
    "            # Padding:\n",
    "            for i, encoding in enumerate(self.encoding):\n",
    "                self.encoding[i] += [pad_id] * (max_Length - len(encoding))\n",
    "\n",
    "        self.max_length = max_Length;\n",
    "        self.encoding = torch.tensor(self.encoding, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoding)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.encoding[index] \n",
    "        y = torch.tensor(self.df.iloc[index]['label'], dtype=torch.long)\n",
    "        return (x, y)\n",
    "\n",
    "    def _getMaxlength(self):\n",
    "        max_Length = 0\n",
    "        for encoding in self.encoding:\n",
    "            if (max_Length < len(encoding)):\n",
    "                max_Length = len(encoding)\n",
    "        return max_Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a03f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = 'my-dataset/train.csv'\n",
    "val_csv_path = 'my-dataset/val.csv'\n",
    "test_csv_path = 'my-dataset/test.csv'\n",
    "\n",
    "train_dataset = SpamDataset(train_csv_path, tokenizer, max_Length=120)\n",
    "val_dataset = SpamDataset(val_csv_path, tokenizer, max_Length=120)\n",
    "test_dataset = SpamDataset(test_csv_path, tokenizer, max_Length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f55639bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True, \n",
    "                              num_workers=0,\n",
    "                              drop_last=True)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=True, \n",
    "                            num_workers=0,\n",
    "                            drop_last=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset, \n",
    "                             batch_size=batch_size, \n",
    "                             shuffle=True, \n",
    "                             num_workers=0,\n",
    "                             drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5daf6b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_dataloader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b586573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Val loader:\")\n",
    "for input_batch, target_batch in val_dataloader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ecef88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"test loader:\")\n",
    "for input_batch, target_batch in test_dataloader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9ed15ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "39\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cfb903",
   "metadata": {},
   "source": [
    "## **Adding `Classification Head` To The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "769cafcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "gpt.to('cpu')\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=NEW_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77ebb96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=50257, bias=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.out_head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a3abcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c507871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing [ENTIRE] model layers:\n",
    "for params in gpt.parameters():\n",
    "    params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fe9cd0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=768, out_features=50257, bias=False)\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(gpt.out_head)\n",
    "print(NEW_CONFIG['emb_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "53fb1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the output layer with `out_features=2`\n",
    "num_classes = 2 # [Spam, NotSpam]\n",
    "gpt.out_head = nn.Linear(in_features=NEW_CONFIG['emb_dim'],\n",
    "                         out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1ec706e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.out_head.weight.requires_grad # Gradient ON: For this last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64f89026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Last Transformer Layer & the last norm layer [Trainable]\n",
    "# \"As it improves model's performance.\" -> @rasbt\n",
    "for params in gpt.trf_blocks[-1].parameters():\n",
    "    params.requires_grad = True\n",
    "for params in gpt.final_norm.parameters():\n",
    "    params.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a83f0e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5859, 0.3797],\n",
       "         [3.6536, 2.2486],\n",
       "         [2.8460, 1.6961],\n",
       "         [2.3279, 1.2662]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the updated model:\n",
    "input = torch.tensor([[5211, 345, 423, 640]])\n",
    "gpt.to('cpu')\n",
    "with torch.no_grad():\n",
    "    output = gpt(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ca096c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3279, 1.2662])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][-1] # We are concerned with the Last output (Spam / Not Spam)\n",
    "# Earlier the last output represents the probability distribution for the next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9cf50ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3279, 1.2662]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a92aede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7430, 0.2570])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the updated model:\n",
    "# Model-Evaluation\n",
    "input = torch.tensor([[5211, 345, 423, 640]])\n",
    "with torch.no_grad():\n",
    "    output = gpt(input)\n",
    "output = output[:, -1, :].squeeze()\n",
    "output = output.softmax(-1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bbb2bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 120])\n",
      "torch.Size([8, 120, 2])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for (x, y) in train_dataloader:\n",
    "    print(x.shape)\n",
    "    output = gpt(x)\n",
    "    print(output.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0bd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0, -1, -1,  0, -1, -1,  0])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn.MSELoss(torch.argmax(output[:, -1, :], dim=-1), y)\n",
    "(torch.argmax(output[:, -1, :], dim=-1) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6b8d512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n",
      "1040\n",
      "0.48365384615384616\n"
     ]
    }
   ],
   "source": [
    "gpt.eval()\n",
    "correct_predictions = 0\n",
    "num_examples = 0\n",
    "for i, (x, y) in enumerate(train_dataloader):\n",
    "    with torch.no_grad(): \n",
    "        logits = gpt(x)[:,-1, :]\n",
    "        num_examples += train_dataloader.batch_size\n",
    "    predicted_labels = logits.argmax(-1)\n",
    "    correct_predictions += ((predicted_labels == y).sum().item())\n",
    "    \n",
    "print(correct_predictions)\n",
    "print(num_examples)\n",
    "print(correct_predictions / num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c56f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.36538461538461\n"
     ]
    }
   ],
   "source": [
    "print((correct_predictions / num_examples) * 100) # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ce2bfd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 43.75%\n",
      "Accuracy: 59.38%\n",
      "Accuracy: 56.25%\n"
     ]
    }
   ],
   "source": [
    "def calc_accuracy_loader(model: GPTModel, loader:DataLoader, num_batch=None):\n",
    "    num_examples = 0 \n",
    "    correct_predictions = 0 \n",
    "    if (num_batch is None):\n",
    "        num_batch = loader.batch_size\n",
    "    else:\n",
    "        num_batch = min(num_batch, loader.batch_size)\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        if i < num_batch:\n",
    "            with torch.no_grad():\n",
    "                logits = model(x)[:, -1, :]\n",
    "            predicted_labels = logits.argmax(-1)\n",
    "            correct_predictions += (predicted_labels == y).sum().item()\n",
    "            num_examples += num_batch\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return (correct_predictions / num_examples)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(gpt, train_dataloader, 10)\n",
    "val_accuracy = calc_accuracy_loader(gpt, val_dataloader, 10)\n",
    "test_accuracy = calc_accuracy_loader(gpt, test_dataloader, 10)\n",
    "\n",
    "print(f'Accuracy: {train_accuracy * 100:.2f}%')\n",
    "print(f'Accuracy: {val_accuracy * 100:.2f}%')\n",
    "print(f'Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2bf33472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f4f703c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(model: GPTModel, device: torch.device, loader:DataLoader, num_batch=None):\n",
    "    model.to(device)\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    if (num_batch is None):\n",
    "        num_batch = loader.batch_size\n",
    "    else:\n",
    "        num_batch = min(num_batch, loader.batch_size)\n",
    "    \n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        if i < num_batch:\n",
    "            loss = calc_loss_batch(x, y, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return (total_loss / num_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f636cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7370148420333862\n",
      "1.3377202033996582\n",
      "1.6092319250106812\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(gpt, device, train_dataloader, 5)\n",
    "    val_loss = calc_loss_loader(gpt, device, val_dataloader, 5)\n",
    "    test_loss = calc_loss_loader(gpt, device, test_dataloader, 5)\n",
    "\n",
    "print(train_loss)\n",
    "print(val_loss)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "02365e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.689, Val loss 0.671\n",
      "Ep 1 (Step 000050): Train loss 0.549, Val loss 0.585\n",
      "Ep 1 (Step 000100): Train loss 0.463, Val loss 0.514\n",
      "Training accuracy: 72.50% | Validation accuracy: 92.50%\n",
      "Ep 2 (Step 000150): Train loss 0.183, Val loss 0.183\n",
      "Ep 2 (Step 000200): Train loss 0.252, Val loss 0.115\n",
      "Ep 2 (Step 000250): Train loss 0.086, Val loss 0.068\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000300): Train loss 0.114, Val loss 0.053\n",
      "Ep 3 (Step 000350): Train loss 0.122, Val loss 0.067\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 4 (Step 000400): Train loss 0.043, Val loss 0.052\n",
      "Ep 4 (Step 000450): Train loss 0.143, Val loss 0.033\n",
      "Ep 4 (Step 000500): Train loss 0.131, Val loss 0.037\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 5 (Step 000550): Train loss 0.024, Val loss 0.021\n",
      "Ep 5 (Step 000600): Train loss 0.028, Val loss 0.033\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Training/Finetuning model: \n",
    "\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "\n",
    "# Starting:\n",
    "num_epochs = 5\n",
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    gpt, train_dataloader, val_dataloader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a9f43d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2bfe9920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "79ed8f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 99.36%\n",
      "Test accuracy: 98.44%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_dataloader, gpt, device)\n",
    "val_accuracy = calc_accuracy_loader(val_dataloader, gpt, device)\n",
    "test_accuracy = calc_accuracy_loader(test_dataloader, gpt, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b64f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model on real data:\n",
    "txt = (\n",
    "    \"You are a winner you have been specially\" \n",
    "    \" selected to receive $2938 cash or a $2000 award.\"\n",
    ")\n",
    "encoding = torch.tensor([tokenizer.encode(txt)])\n",
    "logits = gpt(encoding)\n",
    "answer = torch.argmax(logits[:, -1, :], -1)\n",
    "torch.\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
