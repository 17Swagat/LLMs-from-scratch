{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04677f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c94b7",
   "metadata": {},
   "source": [
    "## **Basic Idea for normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3101d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6342],\n",
      "         [0.4079],\n",
      "         [0.4294],\n",
      "         [0.3939]],\n",
      "\n",
      "        [[0.5814],\n",
      "         [0.4683],\n",
      "         [0.6340],\n",
      "         [0.3814]]]) \n",
      "\n",
      "tensor([[[0.0433],\n",
      "         [0.0765],\n",
      "         [0.0690],\n",
      "         [0.0905]],\n",
      "\n",
      "        [[0.0776],\n",
      "         [0.0980],\n",
      "         [0.0629],\n",
      "         [0.1295]]]) \n",
      "\n",
      "tensor([[[0.2082],\n",
      "         [0.2765],\n",
      "         [0.2627],\n",
      "         [0.3009]],\n",
      "\n",
      "        [[0.2786],\n",
      "         [0.3130],\n",
      "         [0.2508],\n",
      "         [0.3598]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((2, 4, 5))\n",
    "mean = x.mean(dim=-1, keepdim=True)\n",
    "var = x.var(dim=-1, keepdim=True)\n",
    "std = x.std(dim=-1, keepdim=True)\n",
    "\n",
    "print(mean,'\\n')\n",
    "print(var, '\\n')\n",
    "print(std, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad9feee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0000],\n",
      "         [-0.0000],\n",
      "         [-0.0000],\n",
      "         [ 0.0000]],\n",
      "\n",
      "        [[-0.0000],\n",
      "         [ 0.0000],\n",
      "         [ 0.0000],\n",
      "         [-0.0000]]])\n",
      "tensor([[[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((2, 4, 5))\n",
    "mean = x.mean(dim=-1, keepdim=True)\n",
    "var = x.var(dim=-1, keepdim=True)\n",
    "std = x.std(dim=-1, keepdim=True)\n",
    "\n",
    "x_norm = (x - mean) / std\n",
    "print(x_norm.mean(-1, keepdim=True))\n",
    "print(x_norm.var(-1, keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e48b87",
   "metadata": {},
   "source": [
    "## **LayerNorm Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "88eaf0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer Normalization\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        self.eps = 1e-5\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        '''x: 3D Tensor'''\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, keepdim=True, unbiased=False) # unbiased=False => Division by `n`, rather than `n-1`\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        # x_norm = (x - mean) / torch.sqrt(var)\n",
    "        # print(x_norm.)\n",
    "        print(x_norm.mean(-1, keepdims=True))\n",
    "        print(x_norm.var(-1, keepdims=True))\n",
    "        return (x_norm * self.scale + self.shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "810c295a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000],\n",
      "        [-0.0000]])\n",
      "tensor([[1.0000],\n",
      "        [1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# IN action\n",
    "x = torch.randn(2, 129750)\n",
    "ln = LayerNorm(emb_dim=129750)\n",
    "out_norm = ln(x)\n",
    "# print(out_norm.mean(-1, keepdims=True))\n",
    "# print(out_norm.var(-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b26869f",
   "metadata": {},
   "source": [
    "# **`GELU()` Activation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08efa96d",
   "metadata": {},
   "source": [
    "<img src = \"./gelu.png\" width = \"900\" height = \"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bf35f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return (0.5 * x * (1 + torch.tanh(\n",
    "            (torch.sqrt(torch.tensor(2/torch.pi))) + (x + 0.044715 * torch.pow(x, 3))\n",
    "        )))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53c424",
   "metadata": {},
   "source": [
    "# **`FeedForward` Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e12be5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = { \n",
    "    \"vocab_size\": 50257, \n",
    "    \"context_length\": 1024, \n",
    "    \"emb_dim\": 768, \n",
    "    \"n_heads\": 12, \n",
    "    \"n_layers\": 12,  # Transformer-Block-Layers\n",
    "    \"drop_rate\": 0.1, \n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8ebb5ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(config['emb_dim'], 4 * config['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear( 4 * config['emb_dim'], config['emb_dim'])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1fda4220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def09970",
   "metadata": {},
   "source": [
    "# **Skip-Connections**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a6c81cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3882],\n",
       "         [-0.3819],\n",
       "         [-0.3874],\n",
       "         [-0.3842]],\n",
       "\n",
       "        [[-0.3808],\n",
       "         [-0.3821],\n",
       "         [-0.3846],\n",
       "         [-0.3773]],\n",
       "\n",
       "        [[-0.3813],\n",
       "         [-0.3809],\n",
       "         [-0.3837],\n",
       "         [-0.3844]],\n",
       "\n",
       "        [[-0.3794],\n",
       "         [-0.3843],\n",
       "         [-0.3772],\n",
       "         [-0.3861]],\n",
       "\n",
       "        [[-0.3802],\n",
       "         [-0.3799],\n",
       "         [-0.3831],\n",
       "         [-0.3866]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Example_ForSkipConnections(nn.Module):\n",
    "    def __init__(self, skip, layers):\n",
    "        super().__init__()\n",
    "        self.use_skipconnect = skip\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layers[0], layers[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layers[1], layers[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layers[2], layers[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layers[3], layers[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layers[4], layers[5]), GELU()),\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            layer_output = layer(x)\n",
    "            if self.use_skipconnect and x.shape == layer_output.shape:\n",
    "                x += layer_output\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "            \n",
    "\n",
    "layers = [5, 5, 4, 3, 3, 1]\n",
    "x = torch.rand((5, 4, 5))\n",
    "model = Example_ForSkipConnections(True, layers)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "85494d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-1., 0., 1.])\n",
    "model_withSkipConnections = Example_ForSkipConnections(skip=True, layers=[3, 3, 3, 3, 3, 1])\n",
    "model_withoutSkipConnections = Example_ForSkipConnections(skip=False, layers=[3, 3, 3, 3, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ded96d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradient(model, x):\n",
    "    out = model(x)\n",
    "    target = torch.tensor([0.])\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = criterion(out, target)\n",
    "    loss.backward()\n",
    "\n",
    "    for name, params in model.named_parameters():\n",
    "        params: torch.Tensor\n",
    "        \n",
    "        print(f'{name} -> {params.grad.abs().mean().item()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6bfe2eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight -> 0.03002546913921833\n",
      "\n",
      "layers.0.0.bias -> 0.04503820464015007\n",
      "\n",
      "layers.1.0.weight -> 0.08033671975135803\n",
      "\n",
      "layers.1.0.bias -> 0.20734548568725586\n",
      "\n",
      "layers.2.0.weight -> 0.18563634157180786\n",
      "\n",
      "layers.2.0.bias -> 0.6501616835594177\n",
      "\n",
      "layers.3.0.weight -> 0.34845197200775146\n",
      "\n",
      "layers.3.0.bias -> 0.9220051765441895\n",
      "\n",
      "layers.4.0.weight -> 1.416274905204773\n",
      "\n",
      "layers.4.0.bias -> 4.7667927742004395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_gradient(model_withoutSkipConnections, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48061758",
   "metadata": {},
   "source": [
    "# **Transformer Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cb03ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "02778d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(config['emb_dim'], 4 * config['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear( 4 * config['emb_dim'], config['emb_dim'])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "51d2d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        self.eps = 1e-5\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        '''x: 3D Tensor'''\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, keepdim=True, unbiased=False) # unbiased=False => Division by `n`, rather than `n-1`\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return (x_norm * self.scale + self.shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c354cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, n_heads, context_length, dropout=0.5, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % n_heads == 0)\n",
    "\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.d_head = (d_out // n_heads)\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.register_buffer('mask', torch.ones(context_length, context_length).triu(1).bool())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''x: 3D. x => (batch_size, num_tokens, token_embed)'''\n",
    "        b, n_tokens, token_embed = x.shape\n",
    "        assert self.d_in == token_embed\n",
    "        \n",
    "        Q = self.W_q(x) # (b, n_tokens, d_out)\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        Q = Q.view(b, n_tokens, self.n_heads, self.d_head) # (b, n_tokens, n_heads, d_head)\n",
    "        K = K.view(b, n_tokens, self.n_heads, self.d_head) \n",
    "        V = V.view(b, n_tokens, self.n_heads, self.d_head) \n",
    "\n",
    "        Q = Q.transpose(1, 2) # (b, n_heads, n_tokens, d_head)\n",
    "        K = K.transpose(1, 2)\n",
    "        V = V.transpose(1, 2)\n",
    "\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-1, -2)) / self.d_head**0.5 #K.shape[-1]**0.5\n",
    "        attn_scores = attn_scores.masked_fill(self.mask[: n_tokens, : n_tokens], -torch.inf)\n",
    "        attn_weights = attn_scores.softmax(-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vectors = attn_weights @ V\n",
    "        context_vectors = context_vectors.transpose(1, 2)\n",
    "        context_vectors = context_vectors.contiguous().view(b, n_tokens, self.d_out)\n",
    "        return self.out_proj(context_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "05d71900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cccb4d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.attn = MultiheadAttention(\n",
    "            d_in=cfg['emb_dim'],    # 768\n",
    "            d_out=cfg['emb_dim'],   # 768\n",
    "            n_heads=cfg['n_heads'], # 12\n",
    "            context_length=cfg['context_length'], # 1024\n",
    "            dropout=cfg['drop_rate'], # 0.1\n",
    "            qkv_bias=cfg['qkv_bias']\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm_1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm_2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.dropout = nn.Dropout(cfg['drop_rate'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Part 1:\n",
    "        shortcut = x\n",
    "        x = self.norm_1(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        # Part 2:\n",
    "        shortcut = x\n",
    "        x = self.norm_2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0dd18d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0246,  0.3926,  1.2577,  ...,  1.0415, -0.0892,  1.1852],\n",
       "         [ 0.7539,  0.2603,  1.3598,  ...,  0.1263,  0.5215,  0.7429],\n",
       "         [ 0.8341, -0.2646,  1.3030,  ...,  0.4057,  0.1048,  0.6147],\n",
       "         [ 1.4581,  0.5226,  1.0878,  ...,  0.5892,  0.1237,  0.1635]],\n",
       "\n",
       "        [[ 1.0880,  0.7147,  0.4273,  ...,  0.8534,  0.5096,  0.8744],\n",
       "         [ 1.0296,  0.6966,  0.6257,  ...,  0.7547,  0.5791,  1.3049],\n",
       "         [ 1.1526,  1.1987,  0.9486,  ...,  0.2142,  0.7802,  0.5957],\n",
       "         [ 1.0588,  0.5211,  0.6352,  ...,  0.0770,  1.0873,  0.7978]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f00cd0",
   "metadata": {},
   "source": [
    "# **GPT Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "378dd4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0102c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(config['vocab_size'], config['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(config['context_length'], config['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(config['drop_rate'])\n",
    "        self.transf_layers = nn.Sequential(*[TransformerBlock(config) for _ in range(config['n_layers'])])\n",
    "        self.final_norm = LayerNorm(config['emb_dim'])\n",
    "        self.out_head = nn.Linear(config['emb_dim'], config['vocab_size'], bias=False)\n",
    "    \n",
    "    def forward(self, x, show_info=False):\n",
    "        '''x: 2D Matrix'''\n",
    "        batch_size, seq_len = x.shape \n",
    "        tok_emb = self.tok_emb(x) \n",
    "        pos_emb = self.pos_emb(torch.arange(seq_len))\n",
    "        x = tok_emb + pos_emb\n",
    "        if show_info:\n",
    "            print(f'Token-Embed(shape): {tok_emb.shape}')\n",
    "            print(f'POS-Embed(shape): {pos_emb.shape}')\n",
    "            print(f'i/p Before TransfBlocks(shape): {x.shape}')\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.transf_layers(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "bb594087",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_2 = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 1024,\n",
    "    'emb_dim': 768,\n",
    "    'n_heads': 12,\n",
    "    'n_layers': 1, #12,\n",
    "    'drop_rate': 0.1,\n",
    "    'qkv_bias': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d63ecde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4919, 389, 345, 30]\n",
      "[22308, 318, 4171, 13]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "txt1 = 'how are you?'\n",
    "txt2 = 'Sky is blue.'\n",
    "encoding_1 = tokenizer.encode(txt1)\n",
    "encoding_2 = tokenizer.encode(txt2)\n",
    "\n",
    "print(encoding_1)\n",
    "print(encoding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "93b27513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how are you?\n",
      "Sky is blue.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(encoding_1))\n",
    "print(tokenizer.decode(encoding_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e0eb1343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4919,   389,   345,    30],\n",
       "        [22308,   318,  4171,    13]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.tensor([encoding_1, encoding_2])\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "0c2ff4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.8062e-01, -5.9063e-02, -1.0971e-01,  ...,  3.0334e-01,\n",
       "           4.2442e-01,  1.0424e+00],\n",
       "         [ 1.7165e-01,  6.2726e-01, -4.7989e-02,  ...,  1.0843e+00,\n",
       "          -2.7839e-01, -6.6204e-01],\n",
       "         [ 2.3094e-01, -2.7239e-02,  8.7531e-01,  ...,  3.6546e-01,\n",
       "          -4.2931e-02, -1.3892e+00],\n",
       "         [-6.0233e-01, -2.9709e-02,  2.3679e-01,  ..., -1.1108e+00,\n",
       "          -4.1140e-01,  1.1067e+00]],\n",
       "\n",
       "        [[ 8.4541e-01, -4.2585e-01, -2.6646e-01,  ..., -1.8422e-01,\n",
       "          -2.9062e-01,  7.6912e-01],\n",
       "         [-1.4991e-01,  5.9588e-01,  6.0895e-01,  ...,  5.0343e-01,\n",
       "           2.4041e-01,  3.9879e-01],\n",
       "         [ 4.2235e-01,  1.5683e-01,  5.1768e-01,  ..., -3.8709e-01,\n",
       "          -9.5160e-01, -1.3042e+00],\n",
       "         [-9.1603e-02,  1.2957e-01,  5.5106e-01,  ..., -7.3786e-01,\n",
       "          -1.2140e+00, -5.1783e-02]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_2)\n",
    "y = model(batch)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "8a916894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "258a5f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' control'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_1_next_token \n",
    "nxt_token = torch.argmax(y[0][-1].softmax(-1))\n",
    "tokenizer.decode([nxt_token.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d836ce",
   "metadata": {},
   "source": [
    "# **`Experiment`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "e6467682",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "6895d168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([4])\n",
      "tensor([3, 4])\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(0, 5)\n",
    "print(t)\n",
    "print(t[-1:])\n",
    "print(t[-2:])\n",
    "print(t[-10:]) # everything..\n",
    "# Assuming (10) is the context_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "2453613c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15496,   314,   716,   220]])\n"
     ]
    }
   ],
   "source": [
    "txt = \"Hello I am \"\n",
    "encoding = torch.tensor(tokenizer.encode(txt))\n",
    "encoding.unsqueeze_(0)\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c5cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cat(torch.tensor(([1, 2, 3]), torch.tensor([-5])))\n",
    "x1 = torch.tensor([1, 2])\n",
    "x2 = torch.tensor([3, 4])\n",
    "# torch.cat((x1, x2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "8b5a34f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   314,   716,   220],\n",
       "        [  -10,   995,  7510,    30]])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding[1, 0] = -10\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "5a6ae25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = encoding.argmax(-1)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab0b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496],\n",
       "        [ 7510]])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding[torch.arange(encoding.shape[0]), idx].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "70568dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   314,   716,   220],\n",
       "        [25374,   995,  7510,    30]])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "e136bff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1944e-01, -1.4650e-01, -5.3666e-01,  ...,  9.6915e-01,\n",
       "          -2.5227e-01,  8.9651e-02],\n",
       "         [-5.2241e-01,  2.2536e-01, -6.1111e-01,  ...,  9.1724e-01,\n",
       "           2.2657e-01,  2.1270e-01],\n",
       "         [ 8.8319e-02, -7.8109e-02, -1.3477e-02,  ...,  1.2279e+00,\n",
       "           7.6103e-01,  3.7268e-01],\n",
       "         [-9.7600e-02, -1.0451e-01,  6.6069e-01,  ...,  6.9136e-02,\n",
       "          -7.5239e-02, -6.6359e-01]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[15496,   314,   716,   220]])\n",
    "model(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "74f3275f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello I am  trenches\n",
      "Hello I am  trenches digest\n",
      "Hello I am  trenches digest credits\n",
      "Hello I am  trenches digest credits (~\n",
      "Hello I am  trenches digest credits (~ Ud\n",
      "Hello I am  trenches digest credits (~ Udaturated\n",
      "Hello I am  trenches digest credits (~ Udaturated restrain\n",
      "Hello I am  trenches digest credits (~ Udaturated restrain testimonies\n",
      "Hello I am  trenches digest credits (~ Udaturated restrain testimonies Senegal\n",
      "Hello I am  trenches digest credits (~ Udaturated restrain testimonies Senegalanus\n",
      "Hello I am  trenches digest credits (~ Udaturated restrain testimonies SenegalanusSteve\n",
      "Hello I am  trenches digest credits (~ Udaturated restrain testimonies SenegalanusSteve teenagers\n",
      "Hello I am  trenches digest credits (~ Udaturated restrain testimonies SenegalanusSteve teenagers龍�\n",
      "Hello I am  trenches digest credits (~ Udaturated restrain testimonies SenegalanusSteve teenagers龍� PDF\n",
      "Hello I am  trenches digest credits (~ Udaturated restrain testimonies SenegalanusSteve teenagers龍� PDFConfiguration\n"
     ]
    }
   ],
   "source": [
    "txt1 = \"Hello I am \"\n",
    "# txt2 = \"HI world shit?\"\n",
    "encoding1 = tokenizer.encode(txt1)\n",
    "# encoding2 = tokenizer.encode(txt2)\n",
    "encoding = torch.tensor([\n",
    "    encoding1, \n",
    "    # encoding2\n",
    "])\n",
    "# encoding.unsqueeze_(0)\n",
    "\n",
    "max_output_token = 15\n",
    "for i in range(max_output_token):\n",
    "    with torch.no_grad():\n",
    "        out = model(encoding)\n",
    "    logits = out[:, -1, :] \n",
    "    probs = logits.softmax(-1)\n",
    "    idx = probs.argmax(dim=-1) # idx of the token with highest prob. [NOTE: This `idx` acts as the tokenId]\n",
    "    idx.unsqueeze_(0)\n",
    "    encoding =  torch.cat((encoding.squeeze(0), idx.squeeze(0)))\n",
    "    print(tokenizer.decode(encoding.numpy()))\n",
    "    encoding.unsqueeze_(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
