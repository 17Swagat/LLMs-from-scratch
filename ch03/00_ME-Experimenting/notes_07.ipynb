{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ad3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Multihead Attention in a Efficient Way\"\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8788d77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([\n",
    "    [0.43, 0.15, 0.89],\n",
    "    [0.55, 0.87, 0.66],\n",
    "    [0.57, 0.85, 0.64],\n",
    "    [0.22, 0.58, 0.33],\n",
    "    [0.77, 0.25, 0.10],\n",
    "    [0.05, 0.80, 0.55]\n",
    "])\n",
    "\n",
    "batch = torch.stack([inputs, inputs])\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97efc606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 8])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "context_length = 10 # max of tokens the model can process:\n",
    "\n",
    "# batch.shape # (b, num_tokens, token_dim)\n",
    "b, num_tokens, token_dim= batch.shape\n",
    "d_in = 3\n",
    "d_out = 8\n",
    "num_heads = 4\n",
    "d_head = d_out // num_heads\n",
    "\n",
    "W_q = nn.Linear(in_features= d_in, out_features= d_out)\n",
    "W_k = nn.Linear(in_features= d_in, out_features= d_out)\n",
    "W_v = nn.Linear(in_features= d_in, out_features= d_out)\n",
    "\n",
    "queries = W_q(batch) # (2, 6, 8) = (b, num_tokens, d_out)\n",
    "keys = W_k(batch) \n",
    "values = W_v(batch) \n",
    "\n",
    "# Reshaping :\n",
    "queries = queries.view(b, num_tokens, num_heads, d_head)\n",
    "keys = keys.view(b, num_tokens, num_heads, d_head)\n",
    "values = values.view(b, num_tokens, num_heads, d_head)\n",
    "\n",
    "queries.transpose_(1, 2) # (b, num_heads, num_tokens, d_head)\n",
    "keys.transpose_(1, 2)\n",
    "values.transpose_(1, 2)\n",
    "\n",
    "attn_scores = queries @ keys.transpose(-1, -2)\n",
    "mask = torch.ones((context_length, context_length)).triu(diagonal=1).bool()\n",
    "mask_attn_scores = attn_scores.masked_fill(mask[:num_tokens, :num_tokens], -torch.inf)\n",
    "# mask_attn_scores[0][0].softmax(dim=-1).sum(dim=-1, keepdims=True)\n",
    "mask_attn_weights = torch.softmax(mask_attn_scores / d_head**0.5, dim=-1)\n",
    "# mask_attn_weights.shape # (2, 4, 6, 6)\n",
    "# values.shape # (2, 4, 6, 2)\n",
    "# mask_attn_weights = dropout(mask_attn_weights) # ****\n",
    "context_vectors = mask_attn_weights @ values\n",
    "context_vectors.shape # (b, num_heads, num_tokens, d_head)\n",
    "context_vectors.transpose_(1, 2).shape # (b, num_tokens, num_heads,  d_head)\n",
    "context_vectors = context_vectors.contiguous().view(b, num_tokens, d_out)\n",
    "# context_vectors.shape # (2, 6, 8)\n",
    "\n",
    "out_proj = nn.Linear(d_out, d_out)\n",
    "\n",
    "out_proj(context_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ea8e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4778,  0.6357,  0.9619,  0.0515,  0.5443,  0.1522,  0.1753,\n",
       "          -0.9143],\n",
       "         [-0.4642,  0.4034,  0.5549, -0.1379,  0.4325,  0.2282,  0.2022,\n",
       "          -0.4690],\n",
       "         [-0.4756,  0.4119,  0.5055, -0.4186,  0.5354,  0.3641,  0.3838,\n",
       "          -0.2982],\n",
       "         [-0.1830,  0.2517,  0.5895,  0.0918,  0.0767,  0.1906, -0.1340,\n",
       "          -0.3514],\n",
       "         [-0.3252,  0.3469,  0.4782, -0.0962,  0.2970,  0.3436,  0.0971,\n",
       "          -0.3144],\n",
       "         [-0.2796,  0.2638,  0.4168, -0.0473,  0.2336,  0.3241,  0.0175,\n",
       "          -0.2542]],\n",
       "\n",
       "        [[-0.3452,  0.3062,  0.5174,  0.3615,  0.0507, -0.0598, -0.3246,\n",
       "          -0.6409],\n",
       "         [-0.2852,  0.4073,  0.7233, -0.1198,  0.2182,  0.3254, -0.0067,\n",
       "          -0.4223],\n",
       "         [-0.5523,  0.3772,  0.3209, -0.3505,  0.4984,  0.2411,  0.3291,\n",
       "          -0.2988],\n",
       "         [-0.3549,  0.4129,  0.6398, -0.2399,  0.5585,  0.4019,  0.4169,\n",
       "          -0.3652],\n",
       "         [-0.3187,  0.3414,  0.5716, -0.0411,  0.4280,  0.3113,  0.2194,\n",
       "          -0.3988],\n",
       "         [-0.4064,  0.3069,  0.4098, -0.2289,  0.4659,  0.3304,  0.3392,\n",
       "          -0.2449]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context_length: \"Maximum number of tokens that the model can handle.\"\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, qkv_bias=False, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"`d_out` must be divisible by `num_heads`\"\n",
    "        self.W_q = nn.Linear(d_in, d_out)\n",
    "        self.W_k = nn.Linear(d_in, d_out)\n",
    "        self.W_v = nn.Linear(d_in, d_out)\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.d_head = (d_out // num_heads)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.register_buffer('mask', torch.ones(context_length, context_length).triu(diagonal=1).bool())\n",
    "\n",
    "        # out-projection:\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''x: (batch_size, num_tokens, token_dim)'''\n",
    "        b, num_tokens, token_dim = x.shape\n",
    "\n",
    "        queries = self.W_q(x)\n",
    "        keys = self.W_k(x)\n",
    "        values = self.W_v(x) # (b, num_tokens, [d_out])\n",
    "        # Reshaping:\n",
    "        queries = queries.view((b, num_tokens, self.num_heads, self.d_head))\n",
    "        keys = keys.view((b, num_tokens, self.num_heads, self.d_head))\n",
    "        values = values.view((b, num_tokens, self.num_heads, self.d_head))\n",
    "\n",
    "        # Transposing, for making total sense of the Matrix\n",
    "        queries = queries.transpose(1, 2) # (b, num_heads, num_tokens, d_head)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(-1, -2)\n",
    "        masked_attn_scores = attn_scores.masked_fill(self.mask[:num_tokens, :num_tokens], -torch.inf)\n",
    "        masked_attn_weights = torch.softmax(masked_attn_scores / self.d_head**0.5, dim=-1)\n",
    "        masked_attn_weights = self.dropout(masked_attn_weights)\n",
    "        context_vectors = (masked_attn_weights @ values).transpose(1, 2) # (b, num_heads, num_tokens, d_head)\n",
    "        # context_vectors = (b,  num_tokens, num_heads, d_head)\n",
    "        context_vectors = context_vectors.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vectors = self.out_proj(context_vectors)\n",
    "        return context_vectors #.shape \n",
    "\n",
    "mha = MultiheadAttention(d_in=batch.shape[-1], d_out=8, num_heads=4, context_length=10)\n",
    "mha(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699c235",
   "metadata": {},
   "source": [
    "# **Revising:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0265aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "inputs = torch.tensor([\n",
    "    [0.43, 0.15, 0.89],\n",
    "    [0.55, 0.87, 0.66],\n",
    "    [0.57, 0.85, 0.64],\n",
    "    [0.22, 0.58, 0.33],\n",
    "    [0.77, 0.25, 0.10],\n",
    "    [0.05, 0.80, 0.55]\n",
    "])\n",
    "\n",
    "batch = torch.stack([inputs, inputs, inputs])\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "592b3b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 4])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multihead-Attention:\n",
    "torch.manual_seed(42)\n",
    "\n",
    "b, num_tokens, token_embed = batch.shape\n",
    "d_in  = batch.shape[-1] #3\n",
    "d_out = 4\n",
    "num_heads = 2\n",
    "d_head = d_out // num_heads\n",
    "\n",
    "W_q = nn.Linear(in_features= d_in, out_features= d_out)\n",
    "W_k = nn.Linear(in_features= d_in, out_features= d_out)\n",
    "W_v = nn.Linear(in_features= d_in, out_features= d_out)\n",
    "\n",
    "queries = W_q(batch) # (b, num_tokens, d_out)\n",
    "keys = W_k(batch)\n",
    "values = W_v(batch)\n",
    "\n",
    "queries = queries.view(b, num_tokens, num_heads, d_head)\n",
    "keys = keys.view(b, num_tokens, num_heads, d_head)\n",
    "values = values.view(b, num_tokens, num_heads, d_head)\n",
    "\n",
    "queries = queries.transpose(1, 2) # (b, num_heads, num_tokens, d_head)\n",
    "keys = keys.transpose(1, 2)\n",
    "values = values.transpose(1, 2)\n",
    "\n",
    "attn_scores = queries @ keys.transpose(-1, -2)\n",
    "context_length =  10 # Maximum number of tokens that the model can handle\n",
    "mask = torch.ones(context_length, context_length).triu(diagonal=1).bool()\n",
    "mask_attn_scores = attn_scores.masked_fill(mask[:num_tokens, :num_tokens], -torch.inf)\n",
    "mask_attn_weights = torch.softmax(mask_attn_scores / d_head**0.5, dim=-1)\n",
    "\n",
    "dropout = nn.Dropout()\n",
    "mask_attn_weights = dropout(mask_attn_weights)\n",
    "context_vectors = mask_attn_weights @ values\n",
    "context_vectors = context_vectors.transpose(1, 2) # (b, num_tokens, num_heads, d_head)\n",
    "context_vectors = context_vectors.contiguous().view(b, num_tokens, num_heads * d_head)\n",
    "\n",
    "out_proj = nn.Linear(in_features= d_out, out_features=d_out)\n",
    "context_vectors = out_proj(context_vectors).shape\n",
    "\n",
    "context_vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
